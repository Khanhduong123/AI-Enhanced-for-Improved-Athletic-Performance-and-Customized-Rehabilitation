{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28435e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587cfe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from core.dataset import YogaDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a16a7b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label map: {'Garland_Pose': 0, 'Happy_Baby_Pose': 1, 'Head_To_Knee_Pose': 2, 'Lunge_Pose': 3}\n",
      "X_batch shape: torch.Size([4, 100, 33, 3])\n",
      "y_batch shape: torch.Size([4])\n",
      "y_batch values: tensor([1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "json_folder = \"../data/keypoints/public_data\"\n",
    "dataset = YogaDataset(json_folder, max_frames=100)\n",
    "batch_size = 4\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Kiểm tra 1 batch dữ liệu\n",
    "for batch in dataloader:\n",
    "    X_batch, y_batch = batch\n",
    "    print(\"X_batch shape:\", X_batch.shape)  # (batch_size, max_frames, 33, 3)\n",
    "    print(\"y_batch shape:\", y_batch.shape)  # (batch_size,)\n",
    "    print(\"y_batch values:\", y_batch)  # Nhãn của từng sample\n",
    "    break  # Dừng sau batch đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a582b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "from torch import Tensor\n",
    "def _get_clones(mod, n):\n",
    "    return nn.ModuleList([copy.deepcopy(mod) for _ in range(n)])\n",
    "\n",
    "# @dataclass\n",
    "class SelfAttention(nn.Module):\n",
    "    batch_first: bool = True\n",
    "\n",
    "class SPOTERTransformerDecoderLayer(nn.TransformerDecoderLayer):\n",
    "    \"\"\"\n",
    "    Edited TransformerDecoderLayer implementation omitting the redundant self-attention operation as opposed to the\n",
    "    standard implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout, activation):\n",
    "        super(SPOTERTransformerDecoderLayer, self).__init__(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "\n",
    "        # del self.self_attn\n",
    "        self.self_attn =  SelfAttention()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        tgt: Tensor,\n",
    "        memory: Tensor,\n",
    "        tgt_mask: Optional[Tensor] = None,\n",
    "        memory_mask: Optional[Tensor] = None,\n",
    "        tgt_key_padding_mask: Optional[Tensor] = None,\n",
    "        memory_key_padding_mask: Optional[Tensor] = None,\n",
    "        tgt_is_causal: bool = False,\n",
    "        memory_is_causal: bool = False,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        tgt = tgt + self.dropout1(tgt)\n",
    "        tgt = self.norm1(tgt)\n",
    "        tgt2 = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,\n",
    "                                   key_padding_mask=memory_key_padding_mask)[0]\n",
    "        tgt = tgt + self.dropout2(tgt2)\n",
    "        tgt = self.norm2(tgt)\n",
    "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
    "        tgt = tgt + self.dropout3(tgt2)\n",
    "        tgt = self.norm3(tgt)\n",
    "\n",
    "        return tgt\n",
    "\n",
    "\n",
    "class SPOTER(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_dim):\n",
    "        \"\"\"\n",
    "        Implementation of the SPOTER (Sign POse-based TransformER) architecture for sign language recognition from sequence\n",
    "        of skeletal data.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_projection = nn.Linear(100 * 33 * 3, hidden_dim)  # 9900 → 54\n",
    "\n",
    "        self.row_embed = nn.Parameter(torch.rand(50, hidden_dim))\n",
    "        self.pos = nn.Parameter(torch.cat([self.row_embed[0].unsqueeze(0).repeat(1, 1, 1)], dim=-1).flatten(0, 1).unsqueeze(0))\n",
    "        self.class_query = nn.Parameter(torch.rand(1, hidden_dim))\n",
    "        self.transformer = nn.Transformer(hidden_dim, 9, 6, 6) #hidden_dim, num_heads, layer_encoder, layer_decoder\n",
    "        self.linear_class = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        custom_decoder_layer = SPOTERTransformerDecoderLayer(self.transformer.d_model, self.transformer.nhead, 2048, 0.1, \"relu\")\n",
    "        self.transformer.decoder.layers = _get_clones(custom_decoder_layer, self.transformer.decoder.num_layers)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = inputs.flatten(start_dim=1)  # (batch_size, 9900)\n",
    "        h = self.input_projection(h)     # (batch_size, hidden_dim=72)\n",
    "        h = h.unsqueeze(1).float()       # (batch_size, 1, hidden_dim)  [Thêm 1 chiều sequence length]\n",
    "        \n",
    "        # Transformer yêu cầu input có shape (seq_len, batch_size, hidden_dim), nên ta cần hoán vị\n",
    "        h = h.permute(1, 0, 2)  # (1, batch_size, hidden_dim)\n",
    "        # Đảm bảo class_query có batch_size giống h\n",
    "        class_query = self.class_query.unsqueeze(1).repeat(1, h.shape[1], 1)  # (1, batch_size, hidden_dim)\n",
    "        # Đưa vào Transformer\n",
    "        h = self.transformer(h, class_query)  # (1, batch_size, hidden_dim)\n",
    "        h = h.squeeze(0)  # Chuyển về (batch_size, hidden_dim) để phù hợp với linear_class\n",
    "        res = self.linear_class(h)  # (batch_size, num_classes)\n",
    "        return res  # Trả về đúng shape: (batch_size, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d0f3081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spoter(model, dataloader, num_epochs=10, batch_size=4, learning_rate=0.001, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Huấn luyện mô hình SPOTER với tập dữ liệu được truyền vào.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Mô hình SPOTER đã khởi tạo.\n",
    "    - dataset: Dataset đã được tạo (dựa trên class YogaDataset).\n",
    "    - num_epochs: Số epoch huấn luyện (mặc định 10).\n",
    "    - batch_size: Số lượng mẫu mỗi batch (mặc định 4).\n",
    "    - learning_rate: Hệ số học (mặc định 0.001).\n",
    "    - device: 'cuda' nếu có GPU, ngược lại dùng 'cpu'.\n",
    "\n",
    "    Output:\n",
    "    - Trả về mô hình đã được train.\n",
    "    \"\"\"\n",
    "\n",
    "    # Đưa mô hình lên GPU (nếu có)\n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # DataLoader để lấy batch dữ liệu\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Khởi tạo Loss Function và Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Vòng lặp huấn luyện\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            # Đưa dữ liệu lên GPU (nếu có)\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(X_batch).squeeze(1)  # Bỏ chiều 1 để có shape (batch_size, num_classes)\n",
    "            \n",
    "            # Tính loss\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # In loss sau mỗi epoch\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "    return model  # Trả về mô hình đã train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94947ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label map: {'Garland_Pose': 0, 'Happy_Baby_Pose': 1, 'Head_To_Knee_Pose': 2, 'Lunge_Pose': 3}\n",
      "Epoch [1/20], Loss: 1.6335\n",
      "Epoch [2/20], Loss: 1.4375\n",
      "Epoch [3/20], Loss: 1.4143\n",
      "Epoch [4/20], Loss: 1.4650\n",
      "Epoch [5/20], Loss: 1.4277\n",
      "Epoch [6/20], Loss: 1.4293\n",
      "Epoch [7/20], Loss: 1.4461\n",
      "Epoch [8/20], Loss: 1.4269\n",
      "Epoch [9/20], Loss: 1.4218\n",
      "Epoch [10/20], Loss: 1.3877\n",
      "Epoch [11/20], Loss: 1.4361\n",
      "Epoch [12/20], Loss: 1.4101\n",
      "Epoch [13/20], Loss: 1.4141\n",
      "Epoch [14/20], Loss: 1.4202\n",
      "Epoch [15/20], Loss: 1.4128\n",
      "Epoch [16/20], Loss: 1.3956\n",
      "Epoch [17/20], Loss: 1.3910\n",
      "Epoch [18/20], Loss: 1.4157\n",
      "Epoch [19/20], Loss: 1.4044\n",
      "Epoch [20/20], Loss: 1.3999\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo dataset (cần thay đổi đường dẫn dataset phù hợp)\n",
    "json_folder = \"../data/keypoints/public_data\"\n",
    "batch_size = 4\n",
    "dataset = YogaDataset(json_folder, max_frames=100)\n",
    "dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "# Khởi tạo mô hình\n",
    "model = SPOTER(num_classes=4, hidden_dim=72)\n",
    "\n",
    "# Train mô hình\n",
    "trained_model = train_spoter(model, dataloader, num_epochs=20, batch_size=8, learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b948993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
